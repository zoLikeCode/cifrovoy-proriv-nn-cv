{"cells":[{"cell_type":"code","execution_count":2,"id":"084e698f-b67a-4bcf-b5f7-d3afc9998661","metadata":{"id":"084e698f-b67a-4bcf-b5f7-d3afc9998661"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bigil\\OneDrive\\Рабочий стол\\CP\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch.nn.functional as F\n","import random\n","import torch\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader, random_split\n","from segmentation_models_pytorch import utils\n","import segmentation_models_pytorch as smp\n","import cv2\n","from tqdm import tqdm\n","from typing import List, Optional\n","from rasterio.windows import Window"]},{"cell_type":"markdown","id":"25a45071-d7b1-4d11-acf2-ab46e6de204e","metadata":{"id":"25a45071-d7b1-4d11-acf2-ab46e6de204e"},"source":["# Визуализация"]},{"cell_type":"code","execution_count":3,"id":"2dfb8e40","metadata":{},"outputs":[],"source":["seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":4,"id":"0dd7cfb3-a299-4a9e-b60f-abf894c3b587","metadata":{"id":"0dd7cfb3-a299-4a9e-b60f-abf894c3b587"},"outputs":[],"source":["PALLETE = [\n","        [0, 0, 0],\n","        [0, 0, 255],\n","        ]\n","\n","\n","ENCODER = 'resnet18'\n","ENCODER_WEIGHTS = 'imagenet'\n","ACTIVATION = 'sigmoid' \n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","EPOCHS = 5\n","BATCH_SIZE = 32\n","\n","INIT_LR = 0.0005\n","LR_DECREASE_STEP = 15\n","LR_DECREASE_COEF = 2 # LR будет разделен на этот коэф раз в LR_DECREASE_STEP эпох\n"," \n","SIZE = 256\n","CHANELS = 10\n","OVERLAP = 0\n","loss = utils.losses.DiceLoss()\n","\n","CLASSES = [\n","    \"background\",\n","    \"water\"\n","]"]},{"cell_type":"code","execution_count":5,"id":"0ff6620c","metadata":{},"outputs":[],"source":["def get_tiles_with_overlap(image_width: int, image_height: int, \n","                           tile_size: int, overlap: int) -> List[Window]:\n","\n","    step_size = tile_size - overlap\n","    tiles = []\n","    for y in range(0, image_height, step_size):\n","        for x in range(0, image_width, step_size):\n","            window = Window(x, y, tile_size, tile_size)\n","            # Adjust window if it exceeds the image bounds\n","            window = window.intersection(Window(0, 0, image_width, image_height))\n","            tiles.append(window)\n","    return tiles\n","\n","def save_tile(src_dataset: rasterio.io.DatasetReader, window: Window, \n","              output_folder: str, tile_index: int, image_id: int) -> None:\n","    \n","    transform = src_dataset.window_transform(window)\n","    tile_data = src_dataset.read(window=window)\n","    \n","    profile = src_dataset.profile\n","    profile.update({\n","        'driver': 'GTiff',\n","        'height': window.height,\n","        'width': window.width,\n","        'transform': transform\n","    })\n","    \n","    output_filename = os.path.join(output_folder, f\"tile_{image_id}_{tile_index}.tif\")\n","    with rasterio.open(output_filename, 'w', **profile) as dst:\n","        dst.write(tile_data)\n","        \n","def split_image(image_path: str, output_folder: str, mask_path: Optional[str] = None, \n","                tile_size: int = 512, overlap: int = 20, image_id: int = 20) -> None:\n","\n","    with rasterio.open(image_path) as src_image:\n","        image_width = src_image.width\n","        image_height = src_image.height\n","\n","        # Create output directories for images and masks (if available)\n","        images_folder = os.path.join(output_folder, 'images')\n","        os.makedirs(images_folder, exist_ok=True)\n","\n","        if mask_path:\n","            masks_folder = os.path.join(output_folder, 'masks')\n","            os.makedirs(masks_folder, exist_ok=True)\n","\n","        # Get list of tiles with overlap\n","        tiles = get_tiles_with_overlap(image_width, image_height, tile_size, overlap)\n","\n","        # Save image tiles (and mask tiles if provided)\n","        if mask_path:\n","            with rasterio.open(mask_path) as src_mask:\n","                for idx, window in tqdm(enumerate(tiles)):\n","                    save_tile(src_image, window, images_folder, idx, image_id)\n","                    save_tile(src_mask, window, masks_folder, idx, image_id)\n","        else:\n","            for idx, window in tqdm(enumerate(tiles)):\n","                save_tile(src_image, window, images_folder, idx, image_id)"]},{"cell_type":"code","execution_count":7,"id":"82d12297","metadata":{},"outputs":[],"source":["\n","def split_N(image_size: int = SIZE,\n","            overlap: int = 0) -> None:\n","    data_list = ['1', '2', '4', '5', '6_1', '6_2', '9_1', '9_2']\n","    \n","    output_folder = f'train_split_{image_size}/' \n","    for image_id in data_list:\n","        image_path = f'train/images/{image_id}.tif' \n","        mask_path = f'train/masks/{image_id}.tif' \n","\n","        split_image(\n","        image_path=image_path, mask_path=mask_path,\n","        output_folder=output_folder, tile_size=image_size,\n","        overlap=overlap, image_id=image_id\n","        ) \n","split_N()"]},{"cell_type":"markdown","id":"f069825f-fa05-4945-b7ee-6fc7b318cdcc","metadata":{"id":"f069825f-fa05-4945-b7ee-6fc7b318cdcc"},"source":["# Считывание данных"]},{"cell_type":"code","execution_count":8,"id":"207801c1-3820-4e59-84e6-720619d0f64b","metadata":{"id":"207801c1-3820-4e59-84e6-720619d0f64b"},"outputs":[],"source":["def image_padding(image, target_size=SIZE):\n","\n","    height, width = image.shape[1:3]\n","    pad_height = max(0, target_size - height)\n","    pad_width = max(0, target_size - width)\n","    padded_image = np.pad(image, ((0, 0), (0, pad_height),\n","                                  (0, pad_width)), mode='reflect')\n","    return padded_image\n","\n","\n","\n","def mask_padding(mask, target_size=SIZE):\n","\n","    height, width = mask.shape\n","    pad_height = max(0, target_size - height)\n","    pad_width = max(0, target_size - width)\n","    padded_mask = np.pad(mask, ((0, pad_height), (0, pad_width)),\n","                         mode='reflect')\n","    return padded_mask\n","\n","def get_data_list(img_path, delete: Optional[bool] = True):\n","\n","    name = []\n","    for _, _, filenames in os.walk(img_path): # given a directory iterates over the files\n","        for filename in filenames:\n","            f = filename.split('.')[0]\n","            name.append(f)\n","\n","    df =  pd.DataFrame({'id': name}, index = np.arange(0, len(name))\n","                       ).sort_values('id').reset_index(drop=True)\n","    df = df['id'].values\n","\n","    if delete:\n","        return np.delete(df, 0)\n","    else:\n","        return df  "]},{"cell_type":"code","execution_count":9,"id":"6fe7d7ee-79a6-486a-bd38-e6ec14312880","metadata":{"id":"6fe7d7ee-79a6-486a-bd38-e6ec14312880"},"outputs":[],"source":["class WaterDataset(Dataset):\n","    def __init__(self, img_path, mask_path, file_names):\n","        self.img_path = img_path\n","        self.mask_path = mask_path\n","        self.file_names = file_names\n","\n","    def __len__(self):\n","            return len(self.file_names)\n","\n","    def __getitem__(self, idx):\n","        with rasterio.open(self.img_path + self.file_names[idx] + '.tif') as fin:\n","            image = fin.read()\n","        image = image_padding(image).astype(np.float32)\n","\n","        with rasterio.open(self.mask_path + self.file_names[idx] + '.tif') as fin:\n","            mask = fin.read(1)\n","        mask = mask_padding(mask)\n","         \n","\n","        # Преобразуем тип данных изображения в float32\n","        image = image.astype(np.float32)\n","        image = torch.from_numpy(image)\n","\n","        # Преобразуем тип данных маски в long\n","        mask = mask.astype(np.uint8)\n","        mask = torch.from_numpy(mask).long()\n","        mask = mask.unsqueeze(0)\n","        \n","\n","\n","        return image, mask"]},{"cell_type":"code","execution_count":10,"id":"34727910-b2cf-4f72-9725-21c765fae498","metadata":{"id":"34727910-b2cf-4f72-9725-21c765fae498"},"outputs":[],"source":["data_list = get_data_list(f'train_split_{SIZE}/images/')\n","ds = WaterDataset(\n","    img_path=f'train_split_{SIZE}/images/',\n","    mask_path=f'train_split_{SIZE}/masks/',\n","    file_names=data_list\n",")\n","\n","dl = DataLoader(ds)\n"]},{"cell_type":"markdown","id":"55de032f","metadata":{},"source":["## Обучение"]},{"cell_type":"code","execution_count":11,"id":"96afcd4e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Обучение Linknet\n","\n","Epoch: 0\n","train: 100%|██████████| 107/107 [03:05<00:00,  1.73s/it, dice_loss - 0.7765, fscore - 0.53, iou_score - 0.4211]  \n","valid: 100%|██████████| 27/27 [00:45<00:00,  1.68s/it, dice_loss - 0.6497, fscore - 0.7684, iou_score - 0.6483]\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bigil\\OneDrive\\Рабочий стол\\CP\\myenv\\lib\\site-packages\\segmentation_models_pytorch\\base\\model.py:17: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if h % output_stride != 0 or w % output_stride != 0:\n"]},{"name":"stdout","output_type":"stream","text":["Model saved!\n","LR: 0.0005\n","\n","Epoch: 1\n","train: 100%|██████████| 107/107 [02:14<00:00,  1.26s/it, dice_loss - 0.5345, fscore - 0.7457, iou_score - 0.6408]\n","valid: 100%|██████████| 27/27 [00:32<00:00,  1.20s/it, dice_loss - 0.4258, fscore - 0.8257, iou_score - 0.7185]\n","Model saved!\n","LR: 0.0005\n","\n","Epoch: 2\n","train: 100%|██████████| 107/107 [02:14<00:00,  1.26s/it, dice_loss - 0.3528, fscore - 0.786, iou_score - 0.6864] \n","valid: 100%|██████████| 27/27 [00:32<00:00,  1.22s/it, dice_loss - 0.29, fscore - 0.8203, iou_score - 0.7115]  \n","LR: 0.0005\n","\n","Epoch: 3\n","train: 100%|██████████| 107/107 [02:11<00:00,  1.23s/it, dice_loss - 0.2822, fscore - 0.7853, iou_score - 0.6823]\n","valid: 100%|██████████| 27/27 [00:32<00:00,  1.21s/it, dice_loss - 0.2338, fscore - 0.8239, iou_score - 0.7229]\n","Model saved!\n","LR: 0.0005\n","\n","Epoch: 4\n","train: 100%|██████████| 107/107 [02:12<00:00,  1.24s/it, dice_loss - 0.2158, fscore - 0.8273, iou_score - 0.7251]\n","valid: 100%|██████████| 27/27 [00:32<00:00,  1.19s/it, dice_loss - 0.195, fscore - 0.836, iou_score - 0.7376]  \n","Model saved!\n","LR: 0.0005\n"]}],"source":["models_to_test = ['Linknet', 'FPN', 'UnetPlusPlus', 'DeepLabV3']\n","\n","for model_name in models_to_test:\n","\n","    data_list = get_data_list(f'train_split_{SIZE}/images/')\n","    ds = WaterDataset(\n","    img_path=f'train_split_{SIZE}/images/',\n","    mask_path=f'train_split_{SIZE}/masks/',\n","    file_names=data_list\n",")\n","    val_size = int(len(ds) * 0.2)  \n","    train_size = len(ds) - val_size  \n","\n","    train_dataset, val_dataset = random_split(ds, [train_size, val_size])\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    model = getattr(smp, model_name)(\n","        encoder_name=ENCODER, \n","        encoder_weights=ENCODER_WEIGHTS, \n","        classes=1, \n","        activation=ACTIVATION,\n","        in_channels=10\n","    )\n","\n","    metrics = [\n","        utils.metrics.Fscore(),\n","        utils.metrics.IoU()\n","    ]\n","\n","\n","    loss = utils.losses.DiceLoss()\n","    optimizer = torch.optim.Adam([ \n","        dict(params=model.parameters(), lr=INIT_LR),\n","    ])\n","\n","    train_epoch = utils.train.TrainEpoch(\n","        model, \n","        loss=loss, \n","        metrics=metrics, \n","        optimizer=optimizer,\n","        device=DEVICE,\n","        verbose=True,\n","    )\n","\n","    valid_epoch = utils.train.ValidEpoch(\n","        model, \n","        loss=loss, \n","        metrics=metrics, \n","        device=DEVICE,\n","        verbose=True,\n","    )\n","    max_score = 0\n","\n","    loss_logs = {\"train\": [], \"val\": []}\n","    metric_logs = {\"train\": [], \"val\": []}\n","\n","    print(f\"Обучение {model_name}\")\n","    for i in range(0, EPOCHS):\n","\n","        print('\\nEpoch: {}'.format(i))\n","        train_logs = train_epoch.run(train_loader)\n","        train_loss, train_metric, train_metric_IOU = list(train_logs.values())\n","\n","        loss_logs[\"train\"].append(train_loss)\n","        metric_logs[\"train\"].append(train_metric_IOU)\n","\n","        valid_logs = valid_epoch.run(val_loader)\n","        val_loss, val_metric, val_metric_IOU = list(valid_logs.values())\n","\n","        loss_logs[\"val\"].append(val_loss)\n","        metric_logs[\"val\"].append(val_metric_IOU)\n","\n","       \n","        if max_score < valid_logs['iou_score']:\n","            max_score = valid_logs['iou_score']\n","            torch.save(model, f'models/{model_name}.pth')\n","\n","            trace_image = torch.randn(BATCH_SIZE, 10, SIZE, SIZE)\n","            traced_model = torch.jit.trace(model, trace_image.to(DEVICE))\n","\n","            torch.jit.save(traced_model, f'models/{model_name}.pt')\n","            print('Model saved!')\n","\n","        print(\"LR:\", optimizer.param_groups[0]['lr'])\n","        if i > 0 and i % LR_DECREASE_STEP == 0:\n","            print('Decrease decoder learning rate')\n","            optimizer.param_groups[0]['lr'] /= LR_DECREASE_COEF"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":5}
